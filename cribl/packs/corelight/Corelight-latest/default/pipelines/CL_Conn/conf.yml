output: default
streamtags: []
groups:
  3JOA8k:
    name: Parse & Trim
    description: Parse data and remove fields that are not desired for sending to
      destination
    index: 1
    disabled: false
  PmMnc1:
    name: "Enrichment "
    description: Enrichment functions -History description, conn_state and intPscan
      fields are created based on data ingested in this pipeline.
    disabled: false
    index: 2
  Z8Hpz8:
    name: Reduction
    disabled: false
    index: 3
    description: "Remember to always:  Consult Stakeholders: Discuss with your IT,
      networking, and security teams to ensure you aren't discarding valuable
      data. Test in a Non-Production Environment: Before making changes, make
      sure that the removal of any fields does not affect your analytics,
      monitoring, or security incident detection processes adversely."
  YfqmCs:
    name: UID Correlation across all log types
    index: 5
    disabled: true
    description: Uses a Redis server to keep a stateful list of events that have a
      matching UID across all ingested log-types
  NxdEEb:
    name: Elastic Common Schema (ECS)
    description: Elasticsearch ECS normalization
    disabled: true
    index: 7
  2o22xv:
    name: Splunk  Common Information Module (CIM)
    index: 8
    disabled: true
    description: Splunk CIM based on the Network Traffic Data Model
  7aZcnw:
    name: MS Sentinel mappings
    disabled: true
    index: 9
    description: Mapping to MS Sentinel Fields - Sentinel name, Asim & Suffixed name formats
  GRAgxs:
    name: Chronicle Unified Data Model (UDM)
    index: 10
    disabled: true
  dj8Xnw:
    name: OCSF - AWS Security Lake
    description: "Experimental: OCSF Compliance - AWS Security Lake"
    index: 11
    disabled: true
  ZGkPkS:
    name: Cleanup
    disabled: true
    index: 13
    description: Serialization and removal of selected fields to be send to its
      destination(s).
asyncFuncTimeout: 1000
functions:
  - id: comment
    filter: "true"
    disabled: null
    conf:
      comment: "Connection (Conn) Log Processing: This section establishes the
        fundamental Cribl Stream functions dedicated to handling connection
        logs, aiming to enhance processing efficiency. The process involves the
        exclusion of unsuitable logs, standardization of timestamps,
        specification of index and source types, enhancement of `conn_state`
        fields, filtration of internal port scans, and elimination of less
        frequently utilized PCAP fields. Additionally, the procedure excludes
        east/west traffic and events lacking a reply, effectively minimizing
        false positives from legitimate internal port scans. The retained
        pertinent data significantly accelerates SOC analysis processes."
  - id: comment
    filter: "true"
    disabled: false
    conf:
      comment: >-
        Data Format Identification: This function clarifies the data formats
        that are being ingested into the pipeline. The pipeline supports a
        variety of formats, including TSV (Tab-Separated Values), JSON
        (JavaScript Object Notation), Elasticsearch, as well as various agents
        like Splunk UF, Filebeats, and Cribl Edge. Additionally, sources like
        HEC (HTTP Event Collector) and Syslog are also supported.


        It's important to note that the variable Var.log_format() is defined within the Knowledge Base under Global Variables, specifically within the log_format category within this Pack.
    groupId: 3JOA8k
  - id: eval
    filter: "true"
    disabled: false
    conf:
      add:
        - disabled: false
          name: log_format
          value: C.vars.log_format()
    final: false
    groupId: 3JOA8k
  - id: comment
    filter: "true"
    disabled: false
    conf:
      comment: "Handling Raw Syslog Data: In cases where the ingested data comprises
        raw syslog messages without prior preprocessing, the objective is to
        parse these messages into distinct fields that can subsequently be
        utilized by the subsequent functions in the pipeline. This parsing
        process transforms the unprocessed syslog messages into structured data
        for effective downstream processing."
    groupId: 3JOA8k
  - id: serde
    filter: log_format == 'syslog'
    disabled: false
    conf:
      mode: extract
      type: json
      srcField: message
      cleanFields: true
      allowedKeyChars: []
      allowedValueChars: []
      delimChar: \t
      quoteChar: '"'
      escapeChar: \
      nullValue: "-"
      keep: []
      remove: []
      fields: []
    groupId: 3JOA8k
    description: Keep this function enabled
    final: false
  - id: comment
    filter: "true"
    disabled: false
    conf:
      comment: >-
        Processing TSV Formatted Data: In scenarios where the ingested data
        follows the TSV (Tab-Separated Values) format, the procedure involves
        extracting all available fields using the CL_Conn parser from the
        Knowledge section within this Pack. It's important to note that the
        effectiveness of this parser is influenced by the manner in which TSV
        headers are transmitted from the Corelight sensor.


        It's advised to meticulously validate both the types and order of fields being received. This validation process enables you to make necessary adjustments to the existing parser (CL_Conn), such as adding, removing, or reordering fields. This ensures that the parser accurately interprets the TSV data and facilitates seamless downstream processing.
    groupId: 3JOA8k
  - id: serde
    filter: log_format == 'TSV'
    disabled: false
    conf:
      mode: extract
      type: delim
      delimChar: \t
      quoteChar: '"'
      escapeChar: \
      nullValue: "-"
      srcField: _raw
      fields:
        - ts
        - uid
        - id.orig_h
        - id.orig_p
        - id.resp_h
        - id.resp_p
        - proto
        - service
        - duration
        - orig_bytes
        - resp_bytes
        - conn_state
        - local_orig
        - local_resp
        - missed_bytes
        - history
        - orig_pkts
        - orig_ip_bytes
        - resp_pkts
        - resp_ip_bytes
        - tunnel_parents
    groupId: 3JOA8k
    description: Optional - This parser function depends on how TSV headers are
      being sent from the Sensor. Validate the types and fields order to add,
      remove or reorder the fields in the current parser (CL_Conn)
  - id: comment
    filter: "true"
    disabled: false
    conf:
      comment: "Processing Data from HEC Token Format and Agents: In situations where
        the data is ingested through HEC token formats (e.g., Splunk HEC or HTTP
        HEC) or is sourced from agents (such as log shippers like Splunk UF,
        Filebeats or Cribl Edge), the process involves extracting all available
        fields from the incoming data. This step ensures that the relevant
        information contained within the data is effectively captured for
        subsequent processing by the pipeline."
    groupId: 3JOA8k
  - id: serde
    filter: log_format == 'HEC' || log_format == 'Agent'
    disabled: false
    conf:
      mode: extract
      type: json
      srcField: _raw
    groupId: 3JOA8k
  - id: comment
    filter: "true"
    disabled: false
    conf:
      comment: "Selective Event Filtering: The objective here is to filter out events
        that do not match the Corelight dataset or log-type being ingested to
        this pipeline, ensuring that only events of this specific type are
        directed for processing within this dedicated pipeline. By implementing
        this filter, the pipeline exclusively processes events that adhere to
        the defined dataset or log-type, optimizing the relevance and efficiency
        of the processing workflow."
    groupId: 3JOA8k
  - id: drop
    filter: "!_path.startsWith('conn') && !__e['@path'].startsWith('conn') &&
      !sourcetype.includes('conn')"
    disabled: false
    conf: {}
    groupId: 3JOA8k
    description: Drops events that are NOT of the conn log-type
  - id: drop
    filter: _path.includes('_red') || __e['@path'].includes('_red') ||
      sourcetype.match(/_red/)
    disabled: false
    conf: {}
    groupId: 3JOA8k
    description: Optional removal of conn_red logs, will process only conn
  - id: auto_timestamp
    filter: "true"
    disabled: false
    conf:
      srcField: _time
      dstField: _time
      defaultTimezone: UTC
      timeExpression: time.getTime() / 1000
      offset: 0
      maxLen: 150
      defaultTime: now
      latestDateAllowed: +1week
      earliestDateAllowed: -420weeks
    groupId: 3JOA8k
  - id: comment
    filter: "true"
    disabled: false
    conf:
      comment: "Validation and Addition of Index and Source Type Fields: This process
        entails checking for the presence of both the Index and Source Type
        fields within the data. In instances where these fields are absent, the
        function takes corrective action by incorporating them based on
        information from the data source itself and/or the predefined Global
        Variables within the Knowledge / Global Variables section of this Pack.
        This validation and augmentation mechanism ensures that essential
        indexing and categorization attributes are included as required."
    groupId: 3JOA8k
  - id: eval
    filter: "true"
    disabled: true
    conf:
      add:
        - value: C.vars.index.concat('_conn')
          name: index
        - name: sourcetype
          value: sourcetype || 'corelight_'.concat(_path || __e['@path'])
        - disabled: true
          name: host
          value: _system_name
      remove:
        - message
        - log_format
    groupId: 3JOA8k
    description: Define Index and source types - Index Var defined in Knowledge /
      Global Variables
  - id: comment
    filter: "true"
    disabled: false
    conf:
      comment: "Enhanced Custom Code Function for Connection Phases: This custom code
        function has been designed to provide improved descriptions for the
        various phases of a connection. This enhancement is specifically
        tailored to create a more comprehensible read for SOC analysts prior to
        the data being processed by any subsequent analysis systems."
    groupId: PmMnc1
  - id: code
    filter: __e['history']
    disabled: true
    conf:
      maxNumOfIterations: 5000
      activeLogSampleRate: 1
      useUniqueLogChannel: false
      code: >-
        __e['history_description'] = []

        var lookup = C.Lookup('history_conn.csv', 'phase')

        for (var i = 0; i < __e['history'].length; i++) {
          __e['history_description'].push(__e['history'].charAt(i) + ' ' + lookup.match(__e['history'].charAt(i), 'side') + ' - ' + lookup.match(__e['history'].charAt(i), 'description') );
        }
    groupId: PmMnc1
    description: History values placed in an object for easier read.
  - id: comment
    filter: "true"
    disabled: false
    conf:
      comment: >-
        Lookup in corelight_conn_state.csv and Display Matching Value:


        This process involves performing a lookup in the corelight_conn_state.csv file, specifically in the conn_state_desc field. Once a match is found, the corresponding value is retrieved and displayed.
    groupId: PmMnc1
  - id: lookup
    filter: "true"
    disabled: false
    conf:
      matchMode: exact
      reloadPeriodSec: -1
      addToEvent: false
      inFields:
        - eventField: conn_state
          lookupField: code
      ignoreCase: false
      file: corelight_conn_state.csv
      outFields:
        - lookupField: state
          eventField: conn_state_desc
    groupId: PmMnc1
  - id: comment
    filter: "true"
    disabled: false
    conf:
      comment: >-
        Detection and Tagging of Legitimate Internal Port Scans:


        The objective here is to identify and label legitimate internal port scanning activities. This process involves employing specific criteria to differentiate between harmless internal port scans and potentially malicious external ones. The tagging mechanism is used to distinguish and categorize these scans for accurate analysis and investigation.
    groupId: PmMnc1
  - id: eval
    filter: conn_state == "RSTR" && history == "S" && C.Net.isPrivate(__e['id.orig_h'])
    disabled: false
    conf:
      add:
        - disabled: false
          name: int_PScan
          value: "true"
    groupId: PmMnc1
    description: Find and Tag internal port scans
  - id: comment
    filter: "true"
    disabled: false
    conf:
      comment: >-
        VERY IMPORTANT:

        The decision on which fields to remove largely depends on the use case, investigative needs, and the specific environment. We can make some general recommendations for fields that might be considered "less critical" in a typical environment and could potentially be safely removed for data reduction purposes. Keep in mind, these are suggestions, and you should review and confirm based on your own requirements and validate with your team.
    groupId: Z8Hpz8
  - id: comment
    filter: "true"
    disabled: false
    conf:
      comment: >-
        Redundant or Less Informative Timestamps:


        _write_ts: Since you have ts which holds the timestamp of the event, _write_ts might be redundant unless it offers additional context about when the event was written to the log, which may be valuable for troubleshooting or auditing.


        _time: If this timestamp doesn't provide additional value distinct from ts, then it can be considered for removal.
    groupId: Z8Hpz8
  - id: eval
    filter: "true"
    disabled: false
    conf:
      remove:
        - _write_ts
    groupId: Z8Hpz8
  - id: comment
    filter: "true"
    disabled: false
    conf:
      comment: >-
        Network Details:

        orig_l2_addr & resp_l2_addr: Layer 2 (MAC) addresses might not be required if your analysis focuses mainly on Layer 3 (IP) and above. Consider their relevance to your use case.


        orig_cc & resp_cc: These represent country codes. If geo-location isn't a concern for your analysis, they could be candidates for removal. But if you deal with any international regulations or are tracking global activity, these are crucial.
    groupId: Z8Hpz8
  - id: eval
    filter: "true"
    disabled: false
    conf:
      remove:
        - orig_l2_addr
        - resp_l2_addr
        - orig_cc
        - resp_cc
    groupId: Z8Hpz8
  - id: comment
    filter: "true"
    disabled: false
    conf:
      comment: >-
        Connection Metadata:


        tunnel_parents: This field can be useful when analyzing tunneled or encapsulated traffic. However, if you aren't analyzing such traffic, consider its relevance.

        corelight_shunted: If you aren't using Corelight's shunting feature or don't plan on using it, this field might not be necessary.


        history_description & conn_state_desc: These provide human-readable explanations of the connection's history and state. If you have a seasoned team familiar with the shorthand values (like SF and Dd), then these might be redundant. However, for clarity, many teams find these descriptions beneficial.


        spcap.url: If you are not utilizing Corelight's spcap feature for packet capture or this URL isn't actionable in your workflow, it might be a candidate for removal.
    groupId: Z8Hpz8
  - id: eval
    filter: "true"
    disabled: false
    conf:
      remove:
        - tunnel_parents
        - corelight_shunted
    groupId: Z8Hpz8
  - id: comment
    filter: "true"
    disabled: false
    conf:
      comment: >-
        Drop East < > West Internal traffic

        This function will drop any events that starts and ends within an internal IP range (East/West). 

        You can enhance this function by creating a proper list of networks classified by you and match this drop with a lookup function. 


        A good adoption idea would be to use this function to selectively drop events using an specific protocol or from a certain sub-net. You may achieve that by creating lookup tables in the Knowledge session within this Pack and using the Lookup (or C.lookup of inline adoption) function to match either the protocol or networks in your lookup table, you may even create specific lookup tables to drop events from subnet A to subnet B using a protocol at certain time of the day. 

        Explore your options!
    groupId: Z8Hpz8
  - id: drop
    filter: (C.Net.isPrivate(__e['id.orig_h'])) && C.Net.isPrivate(__e['id.resp_h'])
      || (local_orig == true && local_resp == true)
    disabled: false
    conf: {}
    final: false
    groupId: Z8Hpz8
  - id: comment
    filter: "true"
    disabled: false
    conf:
      comment: Connection attempts with no replies
    groupId: Z8Hpz8
  - id: drop
    filter: conn_state == 'S0'
    disabled: false
    conf: {}
    groupId: Z8Hpz8
    description: Drops events with connection atempt with no replies.
  - id: comment
    filter: "true"
    disabled: false
    conf:
      comment: Legit internal port scans can be dropped if your conn_state, history
        fields shows a SYN and a Rest and the session originates from an
        internal IP address.
    groupId: Z8Hpz8
  - id: drop
    filter: conn_state == "RSTR" && history == "S"  &&
      C.Net.isPrivate(__e['id.orig_h'])
    disabled: false
    conf: {}
    groupId: Z8Hpz8
    description: This function will drop events that were identified as an internal
      (routine) port scan (optional)
  - id: comment
    filter: "true"
    disabled: false
    conf:
      comment: For Corelight conn logs in syslog format, consider excluding
        'facility,' 'facilityName,' 'procid,' 'severity,' 'severityName,' and
        'appname.' These fields may not be essential for network connection
        events, simplifying the log format and reducing verbosity.
    groupId: Z8Hpz8
  - id: eval
    filter: "true"
    disabled: false
    conf:
      remove:
        - facility
        - facilityName
        - procid
        - severity
        - severityName
        - appname
    groupId: Z8Hpz8
  - id: comment
    filter: "true"
    disabled: false
    conf:
      comment: Removing Corelight PCAP fields not necessary related to the event but
        keeping its results and status
    groupId: Z8Hpz8
  - id: eval
    filter: "true"
    disabled: false
    conf:
      remove:
        - "'spcap.rule'"
        - "'spcap.trigger'"
    groupId: Z8Hpz8
  - id: comment
    filter: "true"
    disabled: null
    conf:
      comment: 'Optional UID Correlation with Redis: This functionality provides the
        choice to establish UID (Unique Identifier) correlation using Redis.
        This correlation spans across all Corelight datasets / log types that
        are being ingested (including other pipelines). The result of this
        correlation becomes evident in the "Conn" logs, where UIDs that are also
        present in other log types associated with the same event are displayed.
        This feature contributes to an increased level of visibility within your
        system of analysis, augmenting the depth of insight available for SOC
        investigations. By linking UIDs across different log types, the tool
        facilitates more comprehensive and effective scrutiny of security
        events.'
  - id: redis
    filter: "true"
    disabled: true
    conf:
      commands:
        - outField: __corelight_logs
          command: smembers
          keyExpr: "`corelight_logs:${uid}`"
      deploymentType: standalone
      authType: none
      maxBlockSecs: 60
      tlsOptions:
        rejectUnauthorized: false
      url: "`redis://your_redis_ip_address>:6379`"
    description: uid capture to Redis for use on all other log types
    groupId: YfqmCs
  - id: eval
    filter: __corelight_logs.length > 0
    disabled: true
    conf:
      add:
        - disabled: false
          name: corelight_logs
          value: __corelight_logs
    description: Creates the corelight_logs object with all correlated UIDs from all
      log-types ingested
    groupId: YfqmCs
  - id: comment
    filter: "true"
    disabled: null
    conf:
      comment: >-
        Compliance Options - CIM, ECS, MS Sentinel and Chronicle Unified Data
        Model (UDM):

        CIM (Common Information Model):

        Splunk CIM Sourcetype to Data Model Mapping:

        corelight_conn maps to Network_Sessions

        corelight_conn maps to Network_Traffic

        corelight_dhcp maps to Network_Sessions

        corelight_dns maps to Network_Resolution

        corelight_http maps to Web

        corelight_smtp maps to Email

        corelight_ssl maps to Certificates


        ECS (Elastic Common Schema):

        A unified chained pipeline CL_ECS-Chained covers: conn, dns, ssl, http, SSH, SSL, x509, Files, Stepping, RDP, DCE_RDP, SMB_Files, SMB_Mapping, Weird, Notice, Suricata Corelight datasets / log-types.


        MS Sentinel:

        Covers Sentinel Name, Asim and Suffixed name Formats

        All datasets are linked via the Sentinel_cols_mappings.csv table.


        OCSF (Open Cybersecurity Schema Framework) - Network Activity [4001] Class:
  - id: comment
    filter: "true"
    disabled: true
    conf:
      comment: The 'esquery' field is generated with an Elasticsearch query that
        retrieves all UID correlated events from Redis for all log types. This
        query is intended for use in Kibana to display the results, thereby
        helping SOC analysts investigate more efficiently within the system of
        analysis, which in this case is Splunk.
    groupId: NxdEEb
  - id: eval
    filter: corelight_logs
    disabled: true
    conf:
      add:
        - disabled: false
          name: esquery
          value: "`uid:${uid} OR _path:${corelight_logs[0]} OR
            _path:${corelight_logs[1]}`"
    groupId: NxdEEb
  - id: comment
    filter: "true"
    disabled: true
    conf:
      comment: "Uses a Chain function to call another pipeline (CL_ECS-Chained) which
        will process the data. "
    groupId: NxdEEb
  - id: chain
    filter: "true"
    disabled: true
    conf:
      processor: CL_ECS-Chained
    groupId: NxdEEb
    description: Forwards the events to be processed by the CL_ECS-Chained pipeline
      according to Corelight ECS' mappings
  - id: comment
    filter: "true"
    disabled: true
    conf:
      comment: The 'spl' field is created with a Splunk search that retrieves all UID
        correlated events from Redis for all log types. This search is intended
        to be used in order to display the results and assist SOC analysts in
        investigating more efficiently within the system of analysis, which in
        this case is Splunk.
    groupId: 2o22xv
  - id: eval
    filter: corelight_logs
    disabled: true
    conf:
      add:
        - disabled: false
          name: spl
          value: "`index=${index} sourcetype=${sourcetype} uid=${uid}` + (corelight_logs ?
            ` OR index=${index} uid=${uid} sourcetype=` + corelight_logs.join(`
            OR index=${index} uid=${uid} sourcetype=`) : '')"
    groupId: 2o22xv
  - id: comment
    filter: "true"
    disabled: true
    conf:
      comment: "Uses a Chain function to call another pipeline depending on each
        log-type and destination Data Model in Splunk. "
    groupId: 2o22xv
  - id: chain
    filter: "true"
    disabled: true
    conf:
      processor: CIM_Network_Traffic-Chained
    groupId: 2o22xv
    description: Chain function sending all current events to be processed by the
      Network Traffic CIM Data Model specifications
  - id: comment
    filter: "true"
    disabled: true
    conf:
      comment: "Attention: Select one of the three options"
    groupId: 7aZcnw
  - id: comment
    filter: "true"
    disabled: true
    conf:
      comment: Sentinel name format
    groupId: 7aZcnw
  - id: rename
    filter: C.Lookup('Sentinel_cols_mapping.csv','dataset').match(_path)
    disabled: true
    conf:
      wildcardDepth: 4
      renameExpr: C.Lookup('Sentinel_cols_mapping.csv', 'json_name').match(name,
        'sentinel_name')
      baseFields: []
      rename: []
    groupId: 7aZcnw
  - id: comment
    filter: "true"
    disabled: true
    conf:
      comment: Asim format
    groupId: 7aZcnw
  - id: rename
    filter: C.Lookup('Sentinel_cols_mapping.csv','dataset').match(_path)
    disabled: true
    conf:
      wildcardDepth: 4
      renameExpr: C.Lookup('Sentinel_cols_mapping.csv', 'json_name').match(name,
        'asim_name')
      baseFields: []
      rename: []
    groupId: 7aZcnw
  - id: comment
    filter: "true"
    disabled: true
    conf:
      comment: Suffixed name format
    groupId: 7aZcnw
  - id: rename
    filter: C.Lookup('Sentinel_cols_mapping.csv','dataset').match(_path)
    disabled: true
    conf:
      wildcardDepth: 4
      renameExpr: C.Lookup('Sentinel_cols_mapping.csv', 'json_name').match(name,
        'suffixed_name')
      baseFields: []
      rename: []
    groupId: 7aZcnw
  - id: chain
    filter: "true"
    disabled: true
    conf:
      processor: CL_Chronicle_Chained
    groupId: GRAgxs
  - id: chain
    filter: "true"
    disabled: true
    conf:
      processor: CL_Comm_OCSF-Chained
    groupId: dj8Xnw
    description: "** Experimental ** - OCSF mapping and validation for the AWS
      Security Lake"
  - id: comment
    filter: "true"
    disabled: null
    conf:
      comment: >-
        Cleanup Functions and Serialization:

        In the cleanup phase, the serialization process determines the fields that are retained within the `_raw` field. This decision influences the event size, contingent on the number of fields retained or removed, as well as the chosen serialization method. The serialization options include JSON, Key-Value Pair, and CSV formats. The selection of serialization type impacts the data structure and, subsequently, the overall size of the event. 

        Careful consideration is advised to strike a balance between event comprehensiveness and efficient data storage.
  - id: serialize
    filter: "true"
    disabled: true
    conf:
      type: kvp
      fields:
        - "!__*"
        - "!_raw"
        - "*"
      dstField: _raw
      cleanFields: false
    groupId: ZGkPkS
  - id: eval
    filter: _path.includes('conn') || __e['@path'].startsWith('conn') ||
      sourcetype.match(/conn/)
    disabled: true
    conf:
      remove:
        - "*"
      keep:
        - _raw
        - index
        - sourcetype
    description: Cleanup - Remove fields (extracted an in the event) or keep fields
      to be sent to its destination(s).
    groupId: ZGkPkS
